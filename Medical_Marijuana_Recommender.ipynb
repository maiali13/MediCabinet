{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Medical_Marijuana_Recommender.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzhNML7Pm2Cj",
        "colab_type": "text"
      },
      "source": [
        "#Medical Marijuana DS\n",
        "\n",
        "We were tasked with recommending users strains, appropriate dosages, intake method, and the intake schedule using some form of natural language processing. With such limited available data the latter 3 were not feasable. The hope is that with enough user data, a model could be built to predict those things.\n",
        "\n",
        "Given the task and the limited data. We decided a bag of words model was the best approach. Specifically the TFIDF document term matrix combined the a nearest neighbor model. It's possible that a neural network could have provided more accurate results but it's hard to evaluate what a good result is. Even then, the descriptions are so domain specific that it would probably have been more trouble than it was worth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cLkLCpdmyxF",
        "colab_type": "text"
      },
      "source": [
        "## Strain Recommender: TFIDF (BOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLd4xESanLgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the csv\n",
        "# This code has to change to using the api the backend guys built\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Cannabis_Strains_Features.csv')\n",
        "\n",
        "# Dropping 'None' Descriptions\n",
        "df = df[df['Description'] != 'None']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMNk5VHGonOO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f1f1a813-bb6d-42a6-d7d9-b79e6adb6193"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Strain</th>\n",
              "      <th>Type</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Effects</th>\n",
              "      <th>Flavor</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100-Og</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
              "      <td>Earthy,Sweet,Citrus</td>\n",
              "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98-White-Widow</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.7</td>\n",
              "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
              "      <td>Flowery,Violet,Diesel</td>\n",
              "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1024</td>\n",
              "      <td>sativa</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
              "      <td>Spicy/Herbal,Sage,Woody</td>\n",
              "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13-Dawgs</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.2</td>\n",
              "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
              "      <td>Apricot,Citrus,Grapefruit</td>\n",
              "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24K-Gold</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.6</td>\n",
              "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
              "      <td>Citrus,Earthy,Orange</td>\n",
              "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Strain  ...                                        Description\n",
              "0          100-Og  ...  $100 OG is a 50/50 hybrid strain that packs a ...\n",
              "1  98-White-Widow  ...  The ‘98 Aloha White Widow is an especially pot...\n",
              "2            1024  ...  1024 is a sativa-dominant hybrid bred in Spain...\n",
              "3        13-Dawgs  ...  13 Dawgs is a hybrid of G13 and Chemdawg genet...\n",
              "4        24K-Gold  ...  Also known as Kosher Tangie, 24k Gold is a 60%...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOpaAlxnbtyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47d5ebeb-9048-46e2-bd0c-575e0cfa11f6"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2346, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glk1gvfXuavm",
        "colab_type": "text"
      },
      "source": [
        "#### Applying TFIDF Vectorizor along with nearest neighbor model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg63ML1Cu1Qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "6bec8f9f-e751-4263-84f6-8db84640dbf5"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate vectorizer object\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=1500, max_df=.98, min_df=.02)\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "# Similiar to fit_predict\n",
        "tfidfmodel = tfidf.fit_transform(df['Description'])\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(tfidfmodel.todense(), columns=tfidf.get_feature_names())\n",
        "dtm = dtm.drop(dtm.iloc[:, 0:8], axis=1)\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "print(dtm.shape)\n",
        "dtm.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2346, 367)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>afghani</th>\n",
              "      <th>alien</th>\n",
              "      <th>alongside</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>appetite</th>\n",
              "      <th>aroma</th>\n",
              "      <th>aromas</th>\n",
              "      <th>average</th>\n",
              "      <th>away</th>\n",
              "      <th>balanced</th>\n",
              "      <th>berry</th>\n",
              "      <th>best</th>\n",
              "      <th>big</th>\n",
              "      <th>black</th>\n",
              "      <th>blend</th>\n",
              "      <th>blue</th>\n",
              "      <th>blueberry</th>\n",
              "      <th>body</th>\n",
              "      <th>bred</th>\n",
              "      <th>breeder</th>\n",
              "      <th>breeders</th>\n",
              "      <th>bright</th>\n",
              "      <th>brings</th>\n",
              "      <th>bubba</th>\n",
              "      <th>bud</th>\n",
              "      <th>buds</th>\n",
              "      <th>buzz</th>\n",
              "      <th>california</th>\n",
              "      <th>calm</th>\n",
              "      <th>calming</th>\n",
              "      <th>candy</th>\n",
              "      <th>cannabis</th>\n",
              "      <th>cbd</th>\n",
              "      <th>cerebral</th>\n",
              "      <th>cheese</th>\n",
              "      <th>chemdawg</th>\n",
              "      <th>cherry</th>\n",
              "      <th>chocolate</th>\n",
              "      <th>...</th>\n",
              "      <th>sweetness</th>\n",
              "      <th>symptoms</th>\n",
              "      <th>takes</th>\n",
              "      <th>tall</th>\n",
              "      <th>taste</th>\n",
              "      <th>tend</th>\n",
              "      <th>terpene</th>\n",
              "      <th>terpenes</th>\n",
              "      <th>thai</th>\n",
              "      <th>thc</th>\n",
              "      <th>time</th>\n",
              "      <th>times</th>\n",
              "      <th>took</th>\n",
              "      <th>trainwreck</th>\n",
              "      <th>treat</th>\n",
              "      <th>treating</th>\n",
              "      <th>trichome</th>\n",
              "      <th>trichomes</th>\n",
              "      <th>tropical</th>\n",
              "      <th>true</th>\n",
              "      <th>typical</th>\n",
              "      <th>typically</th>\n",
              "      <th>undertones</th>\n",
              "      <th>unique</th>\n",
              "      <th>unknown</th>\n",
              "      <th>uplifting</th>\n",
              "      <th>use</th>\n",
              "      <th>users</th>\n",
              "      <th>varieties</th>\n",
              "      <th>variety</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>weeks</th>\n",
              "      <th>white</th>\n",
              "      <th>widow</th>\n",
              "      <th>winning</th>\n",
              "      <th>won</th>\n",
              "      <th>world</th>\n",
              "      <th>yield</th>\n",
              "      <th>yields</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.158664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23781</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.158565</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.080464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128854</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.452836</td>\n",
              "      <td>0.576801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.267952</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.167612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.18084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.204183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.244822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131176</td>\n",
              "      <td>0.153148</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.27364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.256413</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.213829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187229</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20654</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 367 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   active  activity  afghani  alien  ...  won  world  yield  yields\n",
              "0     0.0       0.0      0.0    0.0  ...  0.0    0.0    0.0     0.0\n",
              "1     0.0       0.0      0.0    0.0  ...  0.0    0.0    0.0     0.0\n",
              "2     0.0       0.0      0.0    0.0  ...  0.0    0.0    0.0     0.0\n",
              "3     0.0       0.0      0.0    0.0  ...  0.0    0.0    0.0     0.0\n",
              "4     0.0       0.0      0.0    0.0  ...  0.0    0.0    0.0     0.0\n",
              "\n",
              "[5 rows x 367 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WQd8Nhv7--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2353cc1c-6dee-4a14-bc36-d6d3e2abfb65"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Fit on DTM\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1TKzFcIwDAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "9d714ee5-c584-4946-c878-370f3c54fe9f"
      },
      "source": [
        "text = [ \"\"\"appetite blueberry blend taste sweetness treat soul mind \"\"\"]\n",
        "\n",
        "text_transformed = tfidf.transform(text)\n",
        "text_transformed = pd.DataFrame(text_transformed.todense(), columns=tfidf.get_feature_names())\n",
        "text_transformed = text_transformed.drop(text_transformed.iloc[:, 0:8], axis=1)\n",
        "text_transformed"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>afghani</th>\n",
              "      <th>alien</th>\n",
              "      <th>alongside</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>appetite</th>\n",
              "      <th>aroma</th>\n",
              "      <th>aromas</th>\n",
              "      <th>average</th>\n",
              "      <th>away</th>\n",
              "      <th>balanced</th>\n",
              "      <th>berry</th>\n",
              "      <th>best</th>\n",
              "      <th>big</th>\n",
              "      <th>black</th>\n",
              "      <th>blend</th>\n",
              "      <th>blue</th>\n",
              "      <th>blueberry</th>\n",
              "      <th>body</th>\n",
              "      <th>bred</th>\n",
              "      <th>breeder</th>\n",
              "      <th>breeders</th>\n",
              "      <th>bright</th>\n",
              "      <th>brings</th>\n",
              "      <th>bubba</th>\n",
              "      <th>bud</th>\n",
              "      <th>buds</th>\n",
              "      <th>buzz</th>\n",
              "      <th>california</th>\n",
              "      <th>calm</th>\n",
              "      <th>calming</th>\n",
              "      <th>candy</th>\n",
              "      <th>cannabis</th>\n",
              "      <th>cbd</th>\n",
              "      <th>cerebral</th>\n",
              "      <th>cheese</th>\n",
              "      <th>chemdawg</th>\n",
              "      <th>cherry</th>\n",
              "      <th>chocolate</th>\n",
              "      <th>...</th>\n",
              "      <th>sweetness</th>\n",
              "      <th>symptoms</th>\n",
              "      <th>takes</th>\n",
              "      <th>tall</th>\n",
              "      <th>taste</th>\n",
              "      <th>tend</th>\n",
              "      <th>terpene</th>\n",
              "      <th>terpenes</th>\n",
              "      <th>thai</th>\n",
              "      <th>thc</th>\n",
              "      <th>time</th>\n",
              "      <th>times</th>\n",
              "      <th>took</th>\n",
              "      <th>trainwreck</th>\n",
              "      <th>treat</th>\n",
              "      <th>treating</th>\n",
              "      <th>trichome</th>\n",
              "      <th>trichomes</th>\n",
              "      <th>tropical</th>\n",
              "      <th>true</th>\n",
              "      <th>typical</th>\n",
              "      <th>typically</th>\n",
              "      <th>undertones</th>\n",
              "      <th>unique</th>\n",
              "      <th>unknown</th>\n",
              "      <th>uplifting</th>\n",
              "      <th>use</th>\n",
              "      <th>users</th>\n",
              "      <th>varieties</th>\n",
              "      <th>variety</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>weeks</th>\n",
              "      <th>white</th>\n",
              "      <th>widow</th>\n",
              "      <th>winning</th>\n",
              "      <th>won</th>\n",
              "      <th>world</th>\n",
              "      <th>yield</th>\n",
              "      <th>yields</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.335943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.402808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.349958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.461861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.334981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.434352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 367 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   active  activity  afghani  alien  ...  won  world  yield  yields\n",
              "0     0.0       0.0      0.0    0.0  ...  0.0    0.0    0.0     0.0\n",
              "\n",
              "[1 rows x 367 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI6xUtTTwury",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "228c3d37-79b3-4bf3-a888-fdd07c219b64"
      },
      "source": [
        "top_five = nn.kneighbors(text_transformed)[1][0]\n",
        "top_five"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 331, 1070,   19,  396, 1212])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S01IOX2Kwz7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "bcce598e-d1c5-4038-823b-296c116d3eeb"
      },
      "source": [
        "# Getting the top 5 results\n",
        "result = []\n",
        "\n",
        "for index in top_five:\n",
        "  result.append(df.iloc[index])\n",
        "\n",
        "result"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Strain                                              Blueberry-Ak\n",
              " Type                                                      hybrid\n",
              " Rating                                                       4.9\n",
              " Effects                  Energetic,Relaxed,Euphoric,Happy,Sleepy\n",
              " Flavor                                   Blueberry,Sweet,Pungent\n",
              " Description    As the name suggests, Blueberry AK is a hybrid...\n",
              " Name: 331, dtype: object,\n",
              " Strain                                                 Ice-Cream\n",
              " Type                                                      hybrid\n",
              " Rating                                                       4.1\n",
              " Effects                  Happy,Relaxed,Uplifted,Focused,Euphoric\n",
              " Flavor                                       Sweet,Vanilla,Woody\n",
              " Description    This indica-dominant 60/40 strain bred by Para...\n",
              " Name: 1071, dtype: object,\n",
              " Strain                                                      A-10\n",
              " Type                                                      indica\n",
              " Rating                                                       3.8\n",
              " Effects                    Relaxed,Focused,Happy,Sleepy,Uplifted\n",
              " Flavor                                      Citrus,Pungent,Sweet\n",
              " Description    A-10 has an earthy, hashy taste that provides ...\n",
              " Name: 19, dtype: object,\n",
              " Strain                                               Bubbleberry\n",
              " Type                                                      hybrid\n",
              " Rating                                                       4.4\n",
              " Effects                    Happy,Relaxed,Focused,Uplifted,Hungry\n",
              " Flavor                                     Sweet,Berry,Blueberry\n",
              " Description    Bubbleberry is a treat for cannabis consumers ...\n",
              " Name: 396, dtype: object,\n",
              " Strain                                                 Kushberry\n",
              " Type                                                      indica\n",
              " Rating                                                       4.3\n",
              " Effects                   Relaxed,Sleepy,Happy,Uplifted,Creative\n",
              " Flavor                                        Berry,Earthy,Lemon\n",
              " Description    Kushberry is the perfect blend of two West Coa...\n",
              " Name: 1213, dtype: object]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDG3oRl7WEwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0662de1e-da5b-46bf-8f53-455519979000"
      },
      "source": [
        "for x in result:\n",
        "  print('\\n',x['Description'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " As the name suggests, Blueberry AK is a hybrid strain that combines the indica-dominant Blueberry with the sativa-dominant AK-47, both popular and potent strains in their own right.  Blueberry AK has a strong musky odor with undertones of berry, and flavors ranging from sweet Kush to the more peppery taste of the AK. The effects of this hybrid are both relaxing and upbeat, often inducing a case of the giggles, and people have used it to treat anxiety, depression, and pain.\n",
            "\n",
            " This indica-dominant 60/40 strain bred by Paradise Seeds creates a great hybrid balance of effects. Much like the frozen treat, Ice Cream has a smooth, creamy taste.\n",
            "\n",
            " A-10 has an earthy, hashy taste that provides a very heavy body stone.  Frequently used to treat insomnia and chronic pain.\n",
            "\n",
            " Bubbleberry is a treat for cannabis consumers on either side of the indica-sativa divide. Combining the sweet, floral taste and aroma of Bubble Gum with the all-star fruity skunkiness of Blueberry, this strain has depth while remaining immensely palatable. Enjoy this strain anytime, day or night, but understand that this strain’s pungent aroma will turn heads from 50 yards away. \n",
            "\n",
            " Kushberry is the perfect blend of two West Coast flavors, Blueberry from Oregon and the OG Kush from LA. The exotic flavor doesn’t rival its strength; it is one of DNA Genetics strongest strains. Kushberry is known for relieving pain, sleeplessness, and appetite loss.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKxnT2oOwAJL",
        "colab_type": "text"
      },
      "source": [
        "## LDA Topic Modelling with Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62U8mE-EzVXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  This was for testing purposes only. LDA topic modelling is not very useful for this dataset.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.test.utils import common_corpus\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamulticore import LdaMulticore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaHzIL_35Abf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gensim tokenizer\n",
        "def tokenize(text):\n",
        "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
        "\n",
        "tokens = []\n",
        "for description in df['Description']:\n",
        "  tokens.append(tokenize(str(description)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB-zU8Px5oPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "29b40b26-a6ed-4c1f-caea-15c581dc3beb"
      },
      "source": [
        "# Creating a df of strain and the tokens\n",
        "df2 = pd.DataFrame(index=df['Strain'], data={'tokens':tokens})\n",
        "df2.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Strain</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100-Og</th>\n",
              "      <td>[og, hybrid, strain, packs, strong, punch, sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98-White-Widow</th>\n",
              "      <td>[aloha, white, widow, especially, potent, cut,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>[sativa, dominant, hybrid, bred, spain, medica...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           tokens\n",
              "Strain                                                           \n",
              "100-Og          [og, hybrid, strain, packs, strong, punch, sup...\n",
              "98-White-Widow  [aloha, white, widow, especially, potent, cut,...\n",
              "1024            [sativa, dominant, hybrid, bred, spain, medica..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32uQeWoI6mMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f353c0b-948f-4007-d79c-ce1b9a7b2d63"
      },
      "source": [
        "# A Dictionary Representation of all the words in our corpus\n",
        "id2word = corpora.Dictionary(df2['tokens'])\n",
        "id2word"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x7f3d69aa6eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCYD7lf4695K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ece6177-db83-4e30-e401-748b5093bde7"
      },
      "source": [
        "id2word.token2id['dank']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIN0u6eC7EMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f1b1c29-8b7a-47c7-e856-4a98e87e0dbc"
      },
      "source": [
        "id2word.doc2bow(tokenize(\"This is a sample message Darcy England England England dank dank dank dank dank  dank drank\"))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(458, 6), (2384, 3), (6751, 1), (6900, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ebuW5Z-7QYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b6221a98-931d-4cd6-9442-d6731d689446"
      },
      "source": [
        "import sys\n",
        "print(sys.getsizeof(id2word))\n",
        "print(sys.getsizeof(tokens))\n",
        "len(id2word.keys())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n",
            "21048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8360"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idoTAAGJ7ax4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's remove extreme values from the dataset\n",
        "id2word.filter_extremes(no_below=5, no_above=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X24D5LFj7fmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08a098ae-b599-45c5-a395-e4a3720ec72a"
      },
      "source": [
        "len(id2word.keys())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xtAH7PL7h53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LdaMulticore(corpus=common_corpus,\n",
        "                   id2word=id2word,\n",
        "                   random_state=723812,\n",
        "                   num_topics = 4,\n",
        "                   passes=10,\n",
        "                   workers=12\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQXteAf9-OVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "0ca4977b-1ad9-452f-9bb4-12bc4728bca8"
      },
      "source": [
        "lda.print_topics()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.002*\"alert\" + 0.002*\"buds\" + 0.002*\"body\" + 0.000*\"green\" + 0.000*\"effect\" + 0.000*\"dark\" + 0.000*\"cerebral\" + 0.000*\"feeling\" + 0.000*\"hybrid\" + 0.000*\"indica\"'),\n",
              " (1,\n",
              "  '0.000*\"hybrid\" + 0.000*\"alert\" + 0.000*\"feeling\" + 0.000*\"cerebral\" + 0.000*\"dark\" + 0.000*\"indica\" + 0.000*\"green\" + 0.000*\"effect\" + 0.000*\"body\" + 0.000*\"buds\"'),\n",
              " (2,\n",
              "  '0.000*\"hybrid\" + 0.000*\"body\" + 0.000*\"buds\" + 0.000*\"alert\" + 0.000*\"indica\" + 0.000*\"large\" + 0.000*\"dark\" + 0.000*\"feeling\" + 0.000*\"green\" + 0.000*\"cerebral\"'),\n",
              " (3,\n",
              "  '0.007*\"effect\" + 0.005*\"indica\" + 0.005*\"green\" + 0.005*\"hybrid\" + 0.004*\"high\" + 0.004*\"large\" + 0.004*\"cerebral\" + 0.004*\"dark\" + 0.004*\"feeling\" + 0.002*\"buds\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Fnh6n0-hkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6f9fd53b-1551-4112-8e39-88acad043528"
      },
      "source": [
        "import re\n",
        "\n",
        "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n",
        "topics = [' '.join(t[0:5]) for t in words]\n",
        "for id, t in enumerate(topics): \n",
        "    print(f\"------ Topic {id} ------\")\n",
        "    print(t, end=\"\\n\\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ Topic 0 ------\n",
            "alert buds body green effect\n",
            "\n",
            "------ Topic 1 ------\n",
            "hybrid alert feeling cerebral dark\n",
            "\n",
            "------ Topic 2 ------\n",
            "hybrid body buds alert indica\n",
            "\n",
            "------ Topic 3 ------\n",
            "effect indica green hybrid high\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eBAIvxJ_LQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff031b2e-8c03-4d78-aaad-81538b342556"
      },
      "source": [
        "!pip3 install pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(lda, common_corpus, id2word)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.3)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.14.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.14)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.34.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.12.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (46.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2487139901671441536528919445\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2487139901671441536528919445_data = {\"mdsDat\": {\"x\": [-0.007197974498969135, 0.001847092666524627, 0.0026366585299028105, 0.0027142233025416952], \"y\": [2.1083630863022183e-05, -0.0002573827585757711, 0.0001830644914207159, 5.323463629202556e-05], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [75.12494659423828, 13.44793701171875, 5.713706970214844, 5.713415622711182]}, \"tinfo\": {\"Term\": [\"alert\", \"buds\", \"body\", \"phantom\", \"meets\", \"probably\", \"underground\", \"widely\", \"years\", \"rebel\", \"dinafem\", \"requires\", \"bent\", \"elevate\", \"infusing\", \"seven\", \"sized\", \"speedy\", \"upwards\", \"warmth\", \"originated\", \"exodus\", \"possibly\", \"preserved\", \"enhancing\", \"drawing\", \"unencumbered\", \"warlock\", \"gum\", \"hybridized\", \"effect\", \"indica\", \"green\", \"hybrid\", \"high\", \"large\", \"cerebral\", \"feeling\", \"dark\", \"buds\", \"body\", \"alert\", \"keeping\", \"stimulation\", \"south\", \"proper\", \"productive\", \"producer\", \"means\", \"life\", \"native\", \"healthy\", \"fairly\", \"dosage\", \"tend\", \"natively\", \"afternoon\", \"latitude\", \"weed\", \"terpenes\", \"alert\", \"buds\", \"body\", \"producer\", \"caution\", \"afternoon\", \"weed\", \"stimulation\", \"south\", \"proper\", \"productive\", \"means\", \"hazy\", \"life\", \"keeping\", \"healthy\", \"fairly\", \"dosage\", \"tend\", \"delight\", \"small\", \"indulge\", \"native\", \"crown\", \"colas\", \"assist\", \"wonderful\", \"stand\", \"smells\", \"senses\", \"green\", \"effect\", \"dark\", \"cerebral\", \"feeling\", \"hybrid\", \"indica\", \"large\", \"high\", \"natively\", \"latitude\", \"terpenes\", \"spices\", \"indulge\", \"delight\", \"caution\", \"afternoon\", \"weed\", \"stimulation\", \"south\", \"proper\", \"productive\", \"producer\", \"means\", \"life\", \"keeping\", \"healthy\", \"fairly\", \"dosage\", \"hazy\", \"small\", \"linger\", \"terpenes\", \"fatigue\", \"crown\", \"colas\", \"assist\", \"wonderful\", \"stand\", \"smells\", \"senses\", \"sea\", \"alert\", \"hybrid\", \"tend\", \"native\", \"feeling\", \"cerebral\", \"dark\", \"natively\", \"indica\", \"green\", \"effect\", \"body\", \"buds\", \"large\", \"high\", \"latitude\", \"spices\", \"indulge\", \"delight\", \"caution\", \"afternoon\", \"weed\", \"stimulation\", \"south\", \"proper\", \"productive\", \"producer\", \"means\", \"life\", \"keeping\", \"healthy\", \"fairly\", \"dosage\", \"hazy\", \"small\", \"linger\", \"terpenes\", \"fatigue\", \"crown\", \"colas\", \"assist\", \"wonderful\", \"stand\", \"smells\", \"senses\", \"sea\", \"hybrid\", \"body\", \"buds\", \"alert\", \"indica\", \"large\", \"dark\", \"feeling\", \"green\", \"cerebral\", \"effect\", \"high\", \"native\", \"tend\", \"natively\", \"latitude\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14746765792369843, 0.11274989694356918, 0.1127200648188591, 0.11226176470518112, 0.0781501904129982, 0.07814697921276093, 0.07793620973825455, 0.07793312519788742, 0.07793591916561127, 0.04350842908024788, 0.04350758343935013, 0.04184723272919655, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008684525266289711, 0.008280414156615734, 0.008048629388213158, 0.008048434741795063, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.0016224734717980027, 0.0016208103625103831, 0.0016202463302761316, 0.0016196357319131494, 0.0016190275782719254, 0.0016154443146660924, 0.001614537090063095, 0.0016142796957865357, 0.0016141236992552876, 0.001613440690562129, 0.001613440690562129, 0.001613440690562129, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0006889045471325517, 0.0007222710410133004, 0.0007377684232778847, 0.0006889045471325517, 0.0006889045471325517, 0.00070423778379336, 0.0007037694449536502, 0.0007034680456854403, 0.0006889045471325517, 0.0006997074815444648, 0.0006989162066020072, 0.0006989126559346914, 0.0006895752158015966, 0.0006894461112096906, 0.0006892664241604507, 0.0006891784141771495, 0.0006889045471325517, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006897497805766761, 0.0006895372644066811, 0.0006895160186104476, 0.0006894997786730528, 0.0006894771358929574, 0.0006893037934787571, 0.0006892972742207348, 0.0006892691017128527, 0.0006892455858178437, 0.000689233944285661, 0.0006892062374390662, 0.0006892034434713423, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866, 0.0006889335345476866], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1504765897989273, 0.11575361341238022, 0.11573070287704468, 0.11530473083257675, 0.08114269375801086, 0.08113983273506165, 0.0809488445520401, 0.08094565570354462, 0.08094893395900726, 0.052936021238565445, 0.052935127168893814, 0.05153941735625267, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.05153941735625267, 0.052936021238565445, 0.052935127168893814, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.11573070287704468, 0.1504765897989273, 0.08094893395900726, 0.0809488445520401, 0.08094565570354462, 0.11530473083257675, 0.11575361341238022, 0.08113983273506165, 0.08114269375801086, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.05153941735625267, 0.11530473083257675, 0.011675804853439331, 0.011675804853439331, 0.08094565570354462, 0.0809488445520401, 0.08094893395900726, 0.011675804853439331, 0.11575361341238022, 0.11573070287704468, 0.1504765897989273, 0.052935127168893814, 0.052936021238565445, 0.08113983273506165, 0.08114269375801086, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.11530473083257675, 0.052935127168893814, 0.052936021238565445, 0.05153941735625267, 0.11575361341238022, 0.08113983273506165, 0.08094893395900726, 0.08094565570354462, 0.11573070287704468, 0.0809488445520401, 0.1504765897989273, 0.08114269375801086, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331, 0.011675804853439331], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.9953999519348145, -5.263899803161621, -5.264100074768066, -5.268199920654297, -5.63040018081665, -5.63040018081665, -5.6331000328063965, -5.633200168609619, -5.6331000328063965, -6.216100215911865, -6.216100215911865, -6.255000114440918, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -7.827499866485596, -6.154799938201904, -6.183199882507324, -6.183199882507324, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.784800052642822, -7.785799980163574, -7.786099910736084, -7.786499977111816, -7.786900043487549, -7.789100170135498, -7.789700031280518, -7.78980016708374, -7.789899826049805, -7.790299892425537, -7.790299892425537, -7.790299892425537, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.785399913787842, -7.738100051879883, -7.716899871826172, -7.785399913787842, -7.785399913787842, -7.763400077819824, -7.764100074768066, -7.764500141143799, -7.785399913787842, -7.769800186157227, -7.770999908447266, -7.770999908447266, -7.78439998626709, -7.784599781036377, -7.784900188446045, -7.784999847412109, -7.785399913787842, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.78410005569458, -7.78439998626709, -7.7845001220703125, -7.7845001220703125, -7.7845001220703125, -7.784800052642822, -7.784800052642822, -7.784800052642822, -7.784900188446045, -7.784900188446045, -7.784900188446045, -7.784900188446045, -7.785299777984619, -7.785299777984619, -7.785299777984619, -7.785299777984619], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.26579999923706055, 0.2597000002861023, 0.2597000002861023, 0.25929999351501465, 0.2484000027179718, 0.2484000027179718, 0.24809999763965607, 0.24809999763965607, 0.24809999763965607, 0.08990000188350677, 0.08990000188350677, 0.07769999653100967, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, -0.009999999776482582, 0.17790000140666962, 0.12280000001192093, 0.12280000001192093, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, -2.260999917984009, -2.5244998931884766, -1.9048999547958374, -1.9053000211715698, -1.9055999517440796, -2.2616000175476074, -2.2660999298095703, -1.9108999967575073, -1.9111000299453735, 0.0272000003606081, 0.0272000003606081, 0.0272000003606081, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, 0.032099999487400055, -1.405400037765503, -2.1893999576568604, 0.032099999487400055, 0.032099999487400055, -1.882099986076355, -1.8827999830245972, -1.8832000494003296, 0.032099999487400055, -2.246299982070923, -2.2472000122070312, -2.509700059890747, -1.4783999919891357, -1.478600025177002, -1.906000018119812, -1.9062000513076782, 0.032099999487400055, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, -2.256700038909912, -1.4783999919891357, -1.4785000085830688, -1.451799988746643, -2.2609000205993652, -1.905900001525879, -1.903499960899353, -1.903499960899353, -2.2611000537872314, -1.9035999774932861, -2.523699998855591, -1.9061000347137451, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197, 0.03220000118017197]}, \"token.table\": {\"Topic\": [], \"Freq\": [], \"Term\": []}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 2, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2487139901671441536528919445\", ldavis_el2487139901671441536528919445_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2487139901671441536528919445\", ldavis_el2487139901671441536528919445_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2487139901671441536528919445\", ldavis_el2487139901671441536528919445_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3     -0.007198  0.000021       1        1  75.124947\n",
              "0      0.001847 -0.000257       2        1  13.447937\n",
              "1      0.002637  0.000183       3        1   5.713707\n",
              "2      0.002714  0.000053       4        1   5.713416, topic_info=          Term      Freq     Total Category  logprob  loglift\n",
              "0        alert  0.000000  0.000000  Default  30.0000  30.0000\n",
              "2         buds  0.000000  0.000000  Default  29.0000  29.0000\n",
              "1         body  0.000000  0.000000  Default  28.0000  28.0000\n",
              "2403   phantom  0.000000  0.000000  Default  27.0000  27.0000\n",
              "1597     meets  0.000000  0.000000  Default  26.0000  26.0000\n",
              "...        ...       ...       ...      ...      ...      ...\n",
              "8         high  0.000689  0.081143   Topic4  -7.7849  -1.9061\n",
              "795     native  0.000689  0.011676   Topic4  -7.7853   0.0322\n",
              "797       tend  0.000689  0.011676   Topic4  -7.7853   0.0322\n",
              "796   natively  0.000689  0.011676   Topic4  -7.7853   0.0322\n",
              "794   latitude  0.000689  0.011676   Topic4  -7.7853   0.0322\n",
              "\n",
              "[194 rows x 6 columns], token_table=Empty DataFrame\n",
              "Columns: [Topic, Freq, Term]\n",
              "Index: [], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQFIkJ7X_uIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32ea161c-bf41-4888-f993-77038e78e6df"
      },
      "source": [
        "test_tokens = ['this', 'herb', 'is', 'dank']\n",
        "test_description = id2word.doc2bow(tokenize(\"Great for back pain and body aches. Might want to snak a litle bit too.\"))\n",
        "\n",
        "# Get topic probabilities\n",
        "lda.get_document_topics(test_description)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.8851233), (1, 0.038107812), (2, 0.038108107), (3, 0.038660783)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}